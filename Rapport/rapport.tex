\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[francais]{babel}
\usepackage{setspace}
\usepackage{graphicx}

\title{PDP \\ - \\ Mesure du rythme cardiaque à partir du flux vidéo de la Kinect 2}

\author{Hereiti \bsc{Hatitio} - Anta \bsc{Mbaye} - Maxime \bsc{Vincent} - Jean-Baptiste \bsc{Rey}}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Cahier des besoins %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Cahier des Besoins}

\section*{Introduction}

Ce projet a pour objectif d'acquérir l'activité cardiaque d'une personne sans contact, uniquement par le biais d'un flux vidéo provenant d'une caméra.
Il sera possible de suivre une ou plusieurs personnes, éventuellement en mouvement, en reconnaissant préalablement leur visage. Un algorithme calculant les pulsations sera appliqué sur les zones suivies, et permettra d'obtenir une estimation du rythme cardiaque du ou des sujets filmés. Les résultats seront stockés sur la machine exécutant le programme et éventuellement envoyés vers des appareils distants.  

\section{Besoins fonctionnels}
Pour spécifier les fonctionnalités proposées et les services à rendre par notre projet, nous avons défini trois grands besoins fonctionnels : récupérer un flux vidéo, l'analyser pour interpréter le rythme cardiaque et sortir le résultat.

\subsection{Récupérer un flux vidéo}
Notre client nous a proposé d'utiliser Kinect 2 pour notre projet : cette caméra présente les avantages de posséder des algorithmes de tracking dans son API et un flux infrarouge, en plus des flux classiques RGB.

Un problème s'est vite présenté : l'API de Kinect 2 est utilisable uniquement sur Windows 8. Nous avons donc eu deux alternatives : changer de périphérique d'entrée et utiliser une webcam, ou utiliser libfreenect2 sur Linux et implémenter nous-même des algorithmes de tracking avec OpenCV 2.4.

La Kinect 2 nous servirait de caméra HD (1080p) en utilisant le flux infrarouge. Ce dernier nous permettra de confronter les résultats du RGB. Nous n'avons pas pu encore tester un flux infrarouge.

\subsection{Analyser un flux vidéo pour interpréter le rythme cardiaque}
Ce besoin fonctionnel principal est divisé en différents sous-besoins fonctionnels.

\subsubsection{Traiter le flux vidéo généré par une caméra}

Appliquer l'algorithme de tracking sur le flux vidéo d'une webcam (RGB ou infrarouge) ou de Kinect 2.

\subsubsection{Détecter la zone de traitement}

Reconnaître au moins un visage, ou plus, l'algorithme de tracking de la Kinect 2 sur Windows 8 étant par exemple capable de prendre en compte six personnes.
L'analyse du rythme cardiaque semble plus efficace (voir prototype) si nous isolons une zone du front.
Si nous rencontrons une difficulté pour le suivi des visages, une alternative serait de tracer un cadre pour que la personne place son visage dans cette zone à analyser.

\subsubsection{Suivre la zone de traitement}

Suivre la zone de traitement lorsque la ou les personnes sont en mouvement. Il est possible de rencontrer une difficulté dans le cas où plusieurs personnes se chevauchent en se déplaçant, il est possible alors de déterminer une zone de mouvement pour chaque personne. Celle-ci limite la zone où le calcul s'effectuera. Si un sujet quitte sa zone attribuée alors le calcul s'arrête jusqu'à ce qu'il revienne dans son cadre.  Cette zone dépendra de l'angle de vision de la caméra.\\

\includegraphics[scale=0.60]{zone_mouvement.png}

\textit{Image tirée d'une publicité Japonaise
}
\subsubsection{Identifier la ou les personnes}

Donner un identifiant numérique à chaque personne détectée : utile pour l'affichage des résultats dans le cas où le programme récupère plusieurs rythmes cardiaques.


\subsection{Affichage du résultat}

Trois cas sont envisageables : le premier consiste à afficher sur une console et écrire dans un fichier log l'entier représentant la pulsation.
Le deuxième consiste à calculer et afficher le nombre de battements par minute dans les mêmes conditions que précédemment. Le troisième consiste à afficher sur une nouvelle fenêtre (GUI) une courbe de pulsation avec la possibilité d'envoyer les résultats sur le réseau.\newline

 \includegraphics[scale=0.5]{gui.png}
\textit{Interface graphique possible.}
\newpage
Le rythme cardiaque obtenu pourra être utilisé sur d'autres appareils externes au programme. 
Nous enverrons donc un entier non chiffré en utilisant le protocole OSC ou LSL qui sera encapsulé dans une trame TCP. Les protocoles OSC et LSL permettent la synchronisation et facilitent le traitement coté client.

On pourra donc implémenter une architecture de type Client-Serveur. L'ordinateur effectuant l'analyse sera considéré comme le serveur et les autres appareils comme les clients.

\subsubsection{Afficher des messages d'erreurs}

Possibilité d'afficher des messages d'avertissement pour l'utilisateur dans le cas où :

\begin{enumerate}
\item [] - Chevauchement de personnes
\item [] - Aucun utilisateur devant la caméra
\item [] - Perte du tracking
\item [] - Aucune caméra détectée 
\item [] - Impossibilité d'envoyer les données (protocole TCP ou autre)
\item [] - Front indétectable

\end{enumerate}
\newpage
\subsection{Schéma UML}
\includegraphics[scale=0.5]{uml.jpeg}
\newpage

\section{Besoins non fonctionnels}

Les besoins non fonctionnels de notre projet se résument en trois parties également.
\subsection{Portabilité}
Le programme doit être portable et modulaire. Notre programme sera découpé en plusieurs parties indépendantes les unes des autres. Ceci assurera la maintenabilité. Par exemple si un algorithme de tracking plus performant venait à être créé il pourrait remplacer le nôtre.

\subsection{Performance}

\subsubsection{Précision du rythme cardiaque}

En testant différents algorithmes de calcul de rythme cardiaque nous prendrons une marge d'erreur de cinq battements par minute. Pour vérifier nos valeurs, nous utiliserons un capteur Arduino ou une électrocardiographie pour avoir de meilleurs résultats.
\subsubsection{Temps du traitement}

Différents tests ont montré qu'il fallait un temps de calcul initial pour pouvoir obtenir les pulsations. Le calcul s'effectue au même moment que la scène filmée, l'affichage quant à lui se fait en différé. Ce temps varie entre 15 et 30 secondes.

\subsection{Ethique}

Notre programme a pour but de calculer le rythme cardiaque d'une personne. Il est donc possible que cette personne n'accepte pas d'être filmée ou que son rythme cardiaque soit visible. De ce fait, un message au lancement du programme apparaîtra prévenant ainsi l'utilisateur.
\newpage
\subsection{Logiciel et système d'exploitation}

\subsubsection{OpenCV}

Nous utiliserons la version 2.4 d'OpenCV qui est portable sur Linux, Windows et Mac. Cette API nous permettra de créé un algorithme de tracking performant pouvant détecter et suivre une à plusieurs personnes.

\subsubsection{libfreenect2}

La bibliothèque libfreenect2 est une alternative libre aux pilotes Microsoft permettant l'accès aux flux RGB et infrarouge Kinect 2, elle sera nécessaire en cas d'utilisation de cette caméra.


\subsubsection{Système d'exploitation}

Notre programme sera compatible avec les distributions : 
\begin{enumerate}
\item[] - Linux Ubuntu 14.04
\item[] - Windows 7, 8 et 8.1
\end{enumerate}
Pour Windows si Kinect 2 est utilisée, Windows 8 ou 8.1 sera obligatoire.

\subsection{Etude de faisabilité}
Les différents algorithmes disponibles dans le dépôt nécessitent l'installation d'OpenCV.
Ces implémentations ont été testées avec une caméra Creative WebCam Live! (640x480 pixels), une caméra logitech QuickCam Chat (352 x 288 pixels) ainsi qu'avec les webcams intégrées d'un ordinateur portable personnel (DELL inspiron 15R résolution webcam 1280x720 pixels, processeur Intel Core i3, 2.3 GHZ, carte graphique : NVDIA GeForce 525 gtm).

Nous n'avons pas pu tester Kinect 2 car nous avons rencontré des difficultés pour l'utiliser. En effet Kinect 2 a besoin de plusieurs paramètres pour être exécutée.
Il faut installer la libfreenect2, posséder un port USB 3 et avoir une carte graphique avec le bon pilote pour pouvoir s'en servir en tant que webcam.
Il faut une carte graphique NVIDIA ou ATI. La technologie optimus de NVIDIA est à ce jour mal gérée pour les distributions Linux. 
\newpage
Voici une liste d'algorithmes que nous avons testé afin de faire une étude de faisabilité : 

\subsubsection{FaceTracker en C++ }
Créé par Jason Saragih (http://jsaragih.org/) et maintenu par Kyle McDonald (http://kylemcdonald.net/)

Le tracking de ce programme permet de suivre une personne. Il est de 10 frames par seconde avec la caméra Créative et de 30 frames par seconde avec la caméra de 1280x720 pixels.
\newline

\subsubsection{HearMonitor en Python}
Par Mossblaser (https://github.com/mossblaser/HeartMonitor).

Ce programme calcule le rythme cardiaque d'une personne immobile. En appuyant sur la touche espace, la zone de traitement est mise à jour dans le cas où la personne s'est déplacée. Le calcul du rythme cardiaque se fait sur une fenêtre de trente secondes. 
Une fois opérationnel, la précision contient un écart de l'ordre de dix battements par minute.

\subsubsection{MultiTrackingPhoto en python}
Auteur Inconnu 

Le programme prend en paramètre une photo(format jpg et png testé) et détecte les visages sur celle-ci.
Son exécution est de l'ordre de 0.3 seconde pour détecter quinze visages sur une photo de 2140x1538 pixels.
Pour une photo de meilleure résolution (3500x1818 pixels) l'exécution est plus lente (0.6 seconde) mais le programme détecte tous les visages (environ 105) de la photo (voir Tests/MultiTrackingPhoto/pic.detect.jpg dans le dépôt svn).

\subsubsection{Webcam-pulse-detector en python}
Écrit par NASA Glenn Research Center (http://www.nasa.gov/centers/glenn)

Ce programme calcule avec une précision de cinq battements par minute d'écart dans une pièce bien éclairée. Il nécessite en moyenne quinze secondes d'initialisation.
Les différents tests que nous avons effectué nous ont montré qu'une caméra possédant une résolution de 1280 x 720 pixels donnent des résultats plus précis qu'une webcam de résolution de 352 x 288 pixels. 
De plus, le tracking est plus performant avec une webcam de meilleure qualité.
\subsection{Diagramme de Gantt}
\includegraphics[scale=0.40]{Gantt.png}
La distribution des tâches n'a pas encore été décidée avec précision.\\ Elle sera effectuée au cours de la phase de conception.
\newpage




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Architecture %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\part*{Architecture}
\setcounter{section}{0}
\section{Modules}

\subsection{Détection périphériques}
Ce module liste les différents périphériques utilisables. Il permet à l'utilisateur d'en sélectionner un.

\subsection{Sélection flux vidéo}

Ce module permet de sélectionner le flux (RGB, IR ou autres) pour appliquer le tracking. Le flux sera ensuite affiché dans l'IHM.

\subsection{Choix du calcul}
Ce module permet la sélection du type de mesure physiologique. Dans notre cas le rythme cardiaque, avec possibilité de rajouter le calcul du rythme respiratoire ou autre.

\subsection{Détection}
A l'aide d'OpenCV, ce module permet de détecter la zone de traitement suivant un choix de l'utilisateur, puis de dessiner le cadre de cette zone.

\subsection{Visage}
Ce module permet d'isoler un visage à partir du flux vidéo.

\subsection{Front}
Ce module isole le front à partir de la zone calculée par le module \textit{Visage}

\subsection{Zone mouvement}

Ce module délimite la zone de mouvement possible sans perte de tracking. Il identifie également les utilisateurs par un ID numérique. Si un utilisateur sort de son cadre, le tracking est perdu, il n'est repris que lorsqu'une nouvelle zone de traitement est détectée.
\vspace*{-0.5in}
\subsection{Calcul}

Ce module effectue le calcul sélectionné dans \textit{Choix du calcul}. Il mesure en boucle le rythme cardiaque tant qu'une zone de traitement est valide.
Le même algorithme est appliqué sur chaque sujet détecté.\newline
\textit{pyfftw} est utilisé pour implémenter l'algorithme basé sur les transformés de Fourier.

\subsection{Traitement résultat}
Ce module récupère les résultats fournis par \textit{Calcul} et les rend compatible avec les modules \textit{Update\_Graphique} et \textit{Réseau}.

\subsection{Réseau}
Ce module encapsule les données de \textit{Traitement résultat} au sein de trames TCP prêtes à être envoyées vers un serveur client.
Il utilisera des protocoles de types OSC et LSL.

\subsection{Avertissements}
En cas d'erreurs produites par les différents modules précédents, un message est envoyé au module \textit{Update\_graphique} qui met à jour l'IHM en spécifiant l'erreur.

\subsection{Update\_graphique}
Ce module correspond à un \textit{Listener}. Il permet de mettre à jour les différents éléments de l'interface graphique.

\subsection{Graphique}
Ce module affiche les différents éléments composant de l'IHM.

\section{Test}
Ce module compare les données calculées via le flux vidéo avec celles d'un capteur de contact (capteur Arduino).

\section{Framework}
\textit{OpenCV} et \textit{pyfftw} sont des bibliothèques qui sont utilisées respectivement par les modules \textit{Détection} et \textit{Calcul}.

\newpage
\vspace*{-1.6in}
\vspace*{-\the\hoffset}
\thispagestyle{empty}
\includegraphics[scale=0.4,angle=90]{archi2.jpeg}
\vspace*{-1in}
\vspace*{-\the\hoffset}

\section{Légendes}
\noindent
\includegraphics[scale=0.5]{bleu.png} : Modules implémentant les besoins fonctionnels\newline
\includegraphics[scale=0.5]{vert.png} : Modules d'affichage graphique\newline
\includegraphics[scale=0.5]{orange.png} : Flux vidéo\newline
\includegraphics[scale=0.5]{rouge.png} : Frameworks\newline
\includegraphics[scale=0.5]{rose.png} :  Module de traitement des erreurs\newline
\includegraphics[scale=0.5]{fleche.png} :  Transitions\newline
\includegraphics[scale=0.5]{fleche_pointille.png} :  Implémentation\newline

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Bibliographie %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\part{Eléments bibliographiques}
\begin{itemize}

\item La documentation \cite{Kinect} Microsoft sur l'appareil Kinect explique le fonctionnement de la machine et l'utilisation des bibliothèques pour programmer avec. Cela nous sera donc utile lorsque nous serons dans la phase développement de notre projet.
\newline
\item L'article \cite{Patel14} présente l'utilisation d'un dispositif permettant de détecter une attaque cardiaque sur un patient sans aucun spécialiste, mais aussi d'appeler les secours. L'appareil Kinect est utilisé pour la détection du rythme cardiaque du patient.
\newline

\item L'article \cite{Ufuk} propose une méthode d'implémentation de mesure de rythme cardiaque à partir d'enregistrements vidéos. A un instant donné, on détecte le visage de l'individu, puis la peau grâce au flux YCbCr. On obtient les signaux PPG en utilisant deux vecteurs de l'espace RGB. Après avoir traité les signaux (filtre passe-bande, transformée de Fourier, …) de chaque fenêtre de la vidéo, on obtient la pulsation cardiaque. Cette article nous propose donc une des orientations possibles que peut prendre notre projet afin de réaliser nos objectifs.
\newline
\item L'article \cite{Cenn} Heart rate monitoring via remote photoplethysmography with motion artifacts reduction montre un système photopléthysmographique qui fonctionne sans contact avec la peau. Les mesures sont fait en temps réel et calcule la fréquence cardiaque.
\newpage
\item Cette référence\cite{Wri03} traite l'Open Sound Control dans toute sa globalité. Les archives de l'université de Berkeley  présentent les domaines d'application de l'OSC, ses spécifications, les langages de programmation avec lesquels on peut l'utiliser. Ce protocole nous sera utile pour synthétiser le son des battements du cœur et les transférer. Dans la référence \cite{Wri03}, nous pouvons constater l'utilisation d'une architecture client/serveur pour l'envoi et la réception des données. 
\item Cet article \cite{Bous} présente les méthodes et les résultats d'un projet consistant à analyser les signaux d'un flux vidéo capturé par une webcam dans le but d'évaluer le rythme cardiaque d'un sujet en temps réel. Cette réalisation inspire notre projet de programmation car l'article y décrit la mise en place des tests expérimentaux, les algorithmes mis en place sur un ordinateur de milieu de gamme pour capturer l'arythmie sinusale respiratoire entraînant la variation de la fréquence cardiaque, en tenant compte des inconvénients induits par la lumière et les mouvements des objets, ainsi que les résultats corrélés avec des capteurs de contact.
Utilisant Kinect, un appareil plus perfectionné qu'une webcam, cet article pourra nous servir de base solide pour obtenir des résultats précis.
\newline
\item L'article \cite{Kran} décrit des méthodes de mesure de pulsation cardiaque, dont la photopléthysmographie. Cette dernière repose sur l'analyse d'un visage d'une ou plusieurs personnes (au repos ou en mouvement lent) à partir d'un fichier vidéo. On obtient des variations du signal pléthysmographique grâce aux flux RGB.
\newline
\item L'article \cite{Verkr} est intéressant dans l'analyse des résultats de photopléthysmographie : détection et modulation de la pulsation cardiaque, cartographie d'amplitude d'impulsion et cartographie de phase, propagation des ondes cardio-vasculaires.
\newline
\item La référence \cite{Sch} présente dans sa globalité une description du LSL, des API pouvant être utilisées. Elle décrit des caractéristiques de fiabilité implémentées par les bibliothèques ainsi que des explications détaillées sur la synchronisation du temps, les formats des fichiers fournis ou conseillés. Elle présente également une liste des codes que l'on pourra utiliser avec par exemple du python, du C++, du C\# ou du Java. 
Nous avons eu besoin de références supplémentaires pour avoir un aperçu plus large sur la documentation et les conseils de programmation sur ce protocole. La première version du LSL a été écrite au Swartz Center for Computational Neuroscience. Nous sommes donc allés chercher la documentation de ces derniers et avons trouvé des cours, des tutoriels sur l'utilisation du LSL. 
\newpage
\item Cette thèse \cite{Wu} décrit la méthode de l'Eularian Video Processing. Cette technique prend une séquence vidéo standard en entrée, et applique une décomposition spatiale, suivie d'un filtrage temporel sur les images. Les signaux résultants peuvent alors être amplifiés visuellement afin de révéler des informations qui ne peuvent être observées à l'oeil nu.
L'Eularian Video Processing peut être exécuté en temps réel, tenir compte des mouvements et de la lumière, pour extraire des signaux vitaux sans contact, comme notamment le rythme cardiaque d'un sujet.
Cette thèse peut donc nous servir dans la réalisation de notre projet de programmation, puisqu'elle s'inscrit dans les mêmes objectifs et y décrit les méthodes utilisées.
\newline
\item Cet article \cite{Tara} montre l'avancée des recherches sur les technologies permettant de surveiller les signes vitaux des patients sans qu'il y ait d'électrodes ou de capteurs placés sur eux. 
L'analyse vidéo des couleurs sur le visage du patient permet d'obtenir ces valeurs. Ceci est en lien avec notre projet.
\end{itemize}

\bibliography{biblio}
\end{document}
